{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os\n",
    "from automathon import NFA\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "import networkx as nx\n",
    "from rouge import Rouge\n",
    "import json\n",
    "\n",
    "import sumy\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sumy\n",
    "\n",
    "[sumy](https://github.com/miso-belica/sumy) is a python library that implements\n",
    "TextRank and other algorithms to summarize text.\n",
    "\n",
    "Sumy implements TextRank algorithm based on the paper [TextRank: Bringing Order into Texts](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/business_articles.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK economy facing 'major risks'\\n\\nThe UK manu...</td>\n",
       "      <td>\"Despite some positive news for the export sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aids and climate top Davos agenda\\n\\nClimate c...</td>\n",
       "      <td>At the same time, about 100,000 people are exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian quake hits European shares\\n\\nShares in ...</td>\n",
       "      <td>The unfolding scale of the disaster in south A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India power shares jump on debut\\n\\nShares in ...</td>\n",
       "      <td>Shares in India's largest power producer, Nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lacroix label bought by US firm\\n\\nLuxury good...</td>\n",
       "      <td>LVMH said the French designer's haute couture ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article   \n",
       "0  UK economy facing 'major risks'\\n\\nThe UK manu...  \\\n",
       "1  Aids and climate top Davos agenda\\n\\nClimate c...   \n",
       "2  Asian quake hits European shares\\n\\nShares in ...   \n",
       "3  India power shares jump on debut\\n\\nShares in ...   \n",
       "4  Lacroix label bought by US firm\\n\\nLuxury good...   \n",
       "\n",
       "                                             Summary  \n",
       "0  \"Despite some positive news for the export sec...  \n",
       "1  At the same time, about 100,000 people are exp...  \n",
       "2  The unfolding scale of the disaster in south A...  \n",
       "3  Shares in India's largest power producer, Nati...  \n",
       "4  LVMH said the French designer's haute couture ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"Article\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_eng = stopwords.words(LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_clean = [re.sub(r'[^\\w\\s]','',sentence.lower()) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = [[words for words in sentence.split() if words not in stopwords_eng] for sentence in sentences_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph: dict[str, list[str]] = {}\n",
    "graph_inv: dict[str, list[str]] = {}\n",
    "in_degree: dict[str, int] = {node: 0 for sentence in sentence_tokens for node in sentence}\n",
    "out_degree: dict[str, int] = {node: 0 for sentence in sentence_tokens for node in sentence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentence_tokens:\n",
    "  for i in range(len(sentence)-1):\n",
    "    word1 = sentence[i]\n",
    "    word2 = sentence[i+1]\n",
    "    \n",
    "    in_degree[word2] += 1\n",
    "    out_degree[word1] += 1\n",
    "    \n",
    "    # Build graph\n",
    "    if word1 not in graph:\n",
    "      graph[word1] = [word2]\n",
    "    elif word2 not in graph[word1]:\n",
    "      graph[word1].append(word2)\n",
    "    \n",
    "    # Build inverse graph\n",
    "    if word2 not in graph_inv:\n",
    "      graph_inv[word2] = [word1]\n",
    "    elif word1 not in graph_inv[word2]:\n",
    "      graph_inv[word2].append(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_graph = json.dumps(graph, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"uk\": [\n",
      "        \"economy\",\n",
      "        \"manufacturing\"\n",
      "    ],\n",
      "    \"economy\": [\n",
      "        \"facing\",\n",
      "        \"still\"\n",
      "    ],\n",
      "    \"facing\": [\n",
      "        \"major\"\n",
      "    ],\n",
      "    \"major\": [\n",
      "        \"risks\",\n",
      "        \"concern\"\n",
      "    ],\n",
      "    \"risks\": [\n",
      "        \"uk\",\n",
      "        \"warned\"\n",
      "    ],\n",
      "    \"manufacturing\": [\n",
      "        \"sector\",\n",
      "        \"also\",\n",
      "        \"bcc\",\n",
      "        \"service\"\n",
      "    ],\n",
      "    \"sector\": [\n",
      "        \"continue\",\n",
      "        \"worrying\",\n",
      "        \"uncertain\"\n",
      "    ],\n",
      "    \"continue\": [\n",
      "        \"face\"\n",
      "    ],\n",
      "    \"face\": [\n",
      "        \"serious\"\n",
      "    ],\n",
      "    \"serious\": [\n",
      "        \"challenges\",\n",
      "        \"problems\"\n",
      "    ],\n",
      "    \"challenges\": [\n",
      "        \"next\"\n",
      "    ],\n",
      "    \"next\": [\n",
      "        \"two\",\n",
      "        \"1218\"\n",
      "    ],\n",
      "    \"two\": [\n",
      "        \"years\"\n",
      "    ],\n",
      "    \"years\": [\n",
      "        \"british\"\n",
      "    ],\n",
      "    \"british\": [\n",
      "        \"chamber\"\n",
      "    ],\n",
      "    \"chamber\": [\n",
      "        \"commerce\"\n",
      "    ],\n",
      "    \"commerce\": [\n",
      "        \"bcc\"\n",
      "    ],\n",
      "    \"bcc\": [\n",
      "        \"said\",\n",
      "        \"found\",\n",
      "        \"noted\",\n",
      "        \"director\"\n",
      "    ],\n",
      "    \"groups\": [\n",
      "        \"quarterly\"\n",
      "    ],\n",
      "    \"quarterly\": [\n",
      "        \"survey\"\n",
      "    ],\n",
      "    \"survey\": [\n",
      "        \"companies\",\n",
      "        \"5196\"\n",
      "    ],\n",
      "    \"companies\": [\n",
      "        \"found\"\n",
      "    ],\n",
      "    \"found\": [\n",
      "        \"exports\",\n",
      "        \"whole\",\n",
      "        \"confidence\"\n",
      "    ],\n",
      "    \"exports\": [\n",
      "        \"picked\",\n",
      "        \"orders\",\n",
      "        \"rise\"\n",
      "    ],\n",
      "    \"picked\": [\n",
      "        \"last\"\n",
      "    ],\n",
      "    \"last\": [\n",
      "        \"three\",\n",
      "        \"year\"\n",
      "    ],\n",
      "    \"three\": [\n",
      "        \"months\"\n",
      "    ],\n",
      "    \"months\": [\n",
      "        \"2004\",\n",
      "        \"unlikely\"\n",
      "    ],\n",
      "    \"2004\": [\n",
      "        \"best\",\n",
      "        \"little\"\n",
      "    ],\n",
      "    \"best\": [\n",
      "        \"levels\"\n",
      "    ],\n",
      "    \"levels\": [\n",
      "        \"eight\",\n",
      "        \"start\"\n",
      "    ],\n",
      "    \"eight\": [\n",
      "        \"years\"\n",
      "    ],\n",
      "    \"rise\": [\n",
      "        \"came\",\n",
      "        \"sufficiently\"\n",
      "    ],\n",
      "    \"came\": [\n",
      "        \"despite\"\n",
      "    ],\n",
      "    \"despite\": [\n",
      "        \"exchange\",\n",
      "        \"positive\",\n",
      "        \"increase\"\n",
      "    ],\n",
      "    \"exchange\": [\n",
      "        \"rates\"\n",
      "    ],\n",
      "    \"rates\": [\n",
      "        \"cited\",\n",
      "        \"five\",\n",
      "        \"kept\"\n",
      "    ],\n",
      "    \"cited\": [\n",
      "        \"major\"\n",
      "    ],\n",
      "    \"however\": [\n",
      "        \"bcc\"\n",
      "    ],\n",
      "    \"whole\": [\n",
      "        \"uk\"\n",
      "    ],\n",
      "    \"still\": [\n",
      "        \"faced\"\n",
      "    ],\n",
      "    \"faced\": [\n",
      "        \"major\"\n",
      "    ],\n",
      "    \"warned\": [\n",
      "        \"growth\"\n",
      "    ],\n",
      "    \"growth\": [\n",
      "        \"set\",\n",
      "        \"slow\",\n",
      "        \"fell\"\n",
      "    ],\n",
      "    \"set\": [\n",
      "        \"slow\",\n",
      "        \"decelerate\"\n",
      "    ],\n",
      "    \"recently\": [\n",
      "        \"forecast\"\n",
      "    ],\n",
      "    \"forecast\": [\n",
      "        \"economic\"\n",
      "    ],\n",
      "    \"economic\": [\n",
      "        \"growth\"\n",
      "    ],\n",
      "    \"slow\": [\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"3\": [\n",
      "        \"2004\"\n",
      "    ],\n",
      "    \"little\": [\n",
      "        \"25\"\n",
      "    ],\n",
      "    \"25\": [\n",
      "        \"2005\"\n",
      "    ],\n",
      "    \"2005\": [\n",
      "        \"2006\"\n",
      "    ],\n",
      "    \"manufacturers\": [\n",
      "        \"domestic\"\n",
      "    ],\n",
      "    \"domestic\": [\n",
      "        \"sales\"\n",
      "    ],\n",
      "    \"sales\": [\n",
      "        \"growth\"\n",
      "    ],\n",
      "    \"fell\": [\n",
      "        \"back\",\n",
      "        \"job\"\n",
      "    ],\n",
      "    \"back\": [\n",
      "        \"slightly\"\n",
      "    ],\n",
      "    \"slightly\": [\n",
      "        \"quarter\"\n",
      "    ],\n",
      "    \"quarter\": [\n",
      "        \"survey\",\n",
      "        \"bcc\",\n",
      "        \"across\"\n",
      "    ],\n",
      "    \"5196\": [\n",
      "        \"firms\"\n",
      "    ],\n",
      "    \"firms\": [\n",
      "        \"found\"\n",
      "    ],\n",
      "    \"employment\": [\n",
      "        \"manufacturing\"\n",
      "    ],\n",
      "    \"also\": [\n",
      "        \"fell\"\n",
      "    ],\n",
      "    \"job\": [\n",
      "        \"expectations\"\n",
      "    ],\n",
      "    \"expectations\": [\n",
      "        \"lowest\"\n",
      "    ],\n",
      "    \"lowest\": [\n",
      "        \"level\"\n",
      "    ],\n",
      "    \"level\": [\n",
      "        \"year\"\n",
      "    ],\n",
      "    \"positive\": [\n",
      "        \"news\"\n",
      "    ],\n",
      "    \"news\": [\n",
      "        \"export\"\n",
      "    ],\n",
      "    \"export\": [\n",
      "        \"sector\"\n",
      "    ],\n",
      "    \"worrying\": [\n",
      "        \"signs\"\n",
      "    ],\n",
      "    \"signs\": [\n",
      "        \"manufacturing\",\n",
      "        \"falling\"\n",
      "    ],\n",
      "    \"results\": [\n",
      "        \"reinforce\"\n",
      "    ],\n",
      "    \"reinforce\": [\n",
      "        \"concern\"\n",
      "    ],\n",
      "    \"concern\": [\n",
      "        \"sectors\"\n",
      "    ],\n",
      "    \"sectors\": [\n",
      "        \"persistent\",\n",
      "        \"although\"\n",
      "    ],\n",
      "    \"persistent\": [\n",
      "        \"inability\"\n",
      "    ],\n",
      "    \"inability\": [\n",
      "        \"sustain\"\n",
      "    ],\n",
      "    \"sustain\": [\n",
      "        \"recovery\"\n",
      "    ],\n",
      "    \"outlook\": [\n",
      "        \"service\"\n",
      "    ],\n",
      "    \"service\": [\n",
      "        \"sector\",\n",
      "        \"sectors\"\n",
      "    ],\n",
      "    \"uncertain\": [\n",
      "        \"despite\"\n",
      "    ],\n",
      "    \"increase\": [\n",
      "        \"exports\",\n",
      "        \"regulations\"\n",
      "    ],\n",
      "    \"orders\": [\n",
      "        \"quarter\"\n",
      "    ],\n",
      "    \"confidence\": [\n",
      "        \"increased\",\n",
      "        \"said\",\n",
      "        \"slowdown\"\n",
      "    ],\n",
      "    \"increased\": [\n",
      "        \"quarter\"\n",
      "    ],\n",
      "    \"across\": [\n",
      "        \"manufacturing\"\n",
      "    ],\n",
      "    \"although\": [\n",
      "        \"overall\"\n",
      "    ],\n",
      "    \"overall\": [\n",
      "        \"failed\"\n",
      "    ],\n",
      "    \"failed\": [\n",
      "        \"reach\"\n",
      "    ],\n",
      "    \"reach\": [\n",
      "        \"levels\"\n",
      "    ],\n",
      "    \"start\": [\n",
      "        \"2004\"\n",
      "    ],\n",
      "    \"reduced\": [\n",
      "        \"threat\"\n",
      "    ],\n",
      "    \"threat\": [\n",
      "        \"interest\",\n",
      "        \"higher\"\n",
      "    ],\n",
      "    \"interest\": [\n",
      "        \"rate\",\n",
      "        \"rates\"\n",
      "    ],\n",
      "    \"rate\": [\n",
      "        \"increases\"\n",
      "    ],\n",
      "    \"increases\": [\n",
      "        \"contributed\"\n",
      "    ],\n",
      "    \"contributed\": [\n",
      "        \"improved\"\n",
      "    ],\n",
      "    \"improved\": [\n",
      "        \"confidence\"\n",
      "    ],\n",
      "    \"bank\": [\n",
      "        \"england\"\n",
      "    ],\n",
      "    \"england\": [\n",
      "        \"raised\"\n",
      "    ],\n",
      "    \"raised\": [\n",
      "        \"interest\"\n",
      "    ],\n",
      "    \"five\": [\n",
      "        \"times\"\n",
      "    ],\n",
      "    \"times\": [\n",
      "        \"november\"\n",
      "    ],\n",
      "    \"november\": [\n",
      "        \"2003\"\n",
      "    ],\n",
      "    \"2003\": [\n",
      "        \"august\"\n",
      "    ],\n",
      "    \"august\": [\n",
      "        \"last\"\n",
      "    ],\n",
      "    \"kept\": [\n",
      "        \"hold\"\n",
      "    ],\n",
      "    \"hold\": [\n",
      "        \"since\"\n",
      "    ],\n",
      "    \"since\": [\n",
      "        \"amid\"\n",
      "    ],\n",
      "    \"amid\": [\n",
      "        \"signs\"\n",
      "    ],\n",
      "    \"falling\": [\n",
      "        \"consumer\"\n",
      "    ],\n",
      "    \"consumer\": [\n",
      "        \"confidence\",\n",
      "        \"spending\"\n",
      "    ],\n",
      "    \"slowdown\": [\n",
      "        \"output\"\n",
      "    ],\n",
      "    \"pressure\": [\n",
      "        \"costs\"\n",
      "    ],\n",
      "    \"costs\": [\n",
      "        \"margins\"\n",
      "    ],\n",
      "    \"margins\": [\n",
      "        \"relentless\"\n",
      "    ],\n",
      "    \"relentless\": [\n",
      "        \"increase\"\n",
      "    ],\n",
      "    \"regulations\": [\n",
      "        \"threat\"\n",
      "    ],\n",
      "    \"higher\": [\n",
      "        \"taxes\"\n",
      "    ],\n",
      "    \"taxes\": [\n",
      "        \"remain\"\n",
      "    ],\n",
      "    \"remain\": [\n",
      "        \"serious\"\n",
      "    ],\n",
      "    \"problems\": [\n",
      "        \"bcc\"\n",
      "    ],\n",
      "    \"director\": [\n",
      "        \"general\"\n",
      "    ],\n",
      "    \"general\": [\n",
      "        \"david\"\n",
      "    ],\n",
      "    \"david\": [\n",
      "        \"frost\"\n",
      "    ],\n",
      "    \"frost\": [\n",
      "        \"said\"\n",
      "    ],\n",
      "    \"spending\": [\n",
      "        \"set\"\n",
      "    ],\n",
      "    \"decelerate\": [\n",
      "        \"significantly\"\n",
      "    ],\n",
      "    \"significantly\": [\n",
      "        \"next\"\n",
      "    ],\n",
      "    \"1218\": [\n",
      "        \"months\"\n",
      "    ],\n",
      "    \"unlikely\": [\n",
      "        \"investment\"\n",
      "    ],\n",
      "    \"investment\": [\n",
      "        \"exports\"\n",
      "    ],\n",
      "    \"sufficiently\": [\n",
      "        \"strongly\"\n",
      "    ],\n",
      "    \"strongly\": [\n",
      "        \"pick\"\n",
      "    ],\n",
      "    \"pick\": [\n",
      "        \"slack\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(pretty_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(graph: dict[str, list[str]], f_set=None, image_name=\"graph_connections\") -> None:\n",
    "  Q :set[str] = set()\n",
    "  sigma = {'-'}\n",
    "  delta: dict[str, dict[str, set[str]]] = {}\n",
    "\n",
    "  for node in graph:\n",
    "    adj_set = set(graph[node])\n",
    "    Q.add(node)\n",
    "    Q = Q.union(adj_set)\n",
    "    \n",
    "    delta[node] = {'-': adj_set}\n",
    "    # for i in range(len(sentence)-1):\n",
    "    #   word1 = sentence[i]\n",
    "    #   word2 = sentence[i+1]\n",
    "      \n",
    "    #   Q.add(word1)\n",
    "    #   Q.add(word2)\n",
    "      \n",
    "    #   if word1 not in delta:\n",
    "    #     delta[word1] = {'-': {word2}}\n",
    "    #   else:\n",
    "    #     delta[word1]['-'].add(word2)\n",
    "\n",
    "  initialState = sentence_tokens[0][0]\n",
    "  if f_set is None:\n",
    "    F = {}\n",
    "  else:\n",
    "    F = f_set\n",
    "\n",
    "  automata = NFA(Q, sigma, delta, initialState, F)\n",
    "  automata.view(image_name)\n",
    "  \n",
    "  ## Delete .gv file\n",
    "  if os.path.isfile(f\"{image_name}.gv\"):\n",
    "    os.remove(f\"{image_name}.gv\")\n",
    "  \n",
    "  ## Rename .gv.png to .png\n",
    "  if os.path.isfile(f\"{image_name}.gv.png\"):\n",
    "    os.rename(f\"{image_name}.gv.png\", f\"{image_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(sentence_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding articulation points in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation adapted from: https://cp-algorithms.com/graph/cutpoints.html#implementation\n",
    "timer = 0\n",
    "\n",
    "def find_cutpoints(graph: dict[str, list[str]]) -> set[str]:\n",
    "  global timer\n",
    "  visited: dict[str, bool] = {}\n",
    "  tin: dict[str, int] = {}\n",
    "  low: dict[str, int] = {}\n",
    "  timer = 0\n",
    "  cut_points: set[str] = set()\n",
    "  \n",
    "  def dfs(v: str, p: str = \"\") -> None:\n",
    "    global timer\n",
    "    visited[v] = True\n",
    "    tin[v] = low[v] = timer\n",
    "    timer += 1\n",
    "    children_count = 0\n",
    "    \n",
    "    if v not in graph:\n",
    "      return\n",
    "    \n",
    "    for to in graph[v]:\n",
    "      if to == p:\n",
    "        continue\n",
    "      if visited[to]:\n",
    "        low[v] = min(low[v], tin[to])\n",
    "      else:\n",
    "        dfs(to, v)\n",
    "        low[v] = min(low[v], low[to])\n",
    "        if low[v] >= tin[v] and p != \"\":\n",
    "          cut_points.add(v)\n",
    "        children_count += 1\n",
    "    \n",
    "    if p == \"\" and children_count > 1:\n",
    "      cut_points.add(v)\n",
    "  \n",
    "  for node in graph:\n",
    "    visited[node] = False\n",
    "    tin[node] = -1\n",
    "    low[node] = -1\n",
    "    for adj in graph[node]:\n",
    "      visited[adj] = False\n",
    "      tin[adj] = -1\n",
    "      low[adj] = -1\n",
    "      \n",
    "  for v in graph:\n",
    "    if not visited[v]:\n",
    "      dfs(v)\n",
    "  \n",
    "  return cut_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_points = find_cutpoints(graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2005',\n",
       " '25',\n",
       " 'bcc',\n",
       " 'inability',\n",
       " 'little',\n",
       " 'persistent',\n",
       " 'pick',\n",
       " 'sectors',\n",
       " 'slowdown',\n",
       " 'strongly',\n",
       " 'sufficiently',\n",
       " 'sustain'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(graph=graph, f_set=cut_points, image_name=\"graph_connections_cutpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut point: pick - in_degree: 1 - out_degree: 1\n",
      "Cut point: bcc - in_degree: 5 - out_degree: 6\n",
      "Cut point: inability - in_degree: 1 - out_degree: 1\n",
      "Cut point: sufficiently - in_degree: 1 - out_degree: 1\n",
      "Cut point: little - in_degree: 1 - out_degree: 1\n",
      "Cut point: 25 - in_degree: 1 - out_degree: 1\n",
      "Cut point: persistent - in_degree: 1 - out_degree: 1\n",
      "Cut point: sectors - in_degree: 2 - out_degree: 2\n",
      "Cut point: sustain - in_degree: 1 - out_degree: 1\n",
      "Cut point: 2005 - in_degree: 1 - out_degree: 1\n",
      "Cut point: slowdown - in_degree: 1 - out_degree: 1\n",
      "Cut point: strongly - in_degree: 1 - out_degree: 1\n"
     ]
    }
   ],
   "source": [
    "for cut_point in cut_points:\n",
    "  print(f\"Cut point: {cut_point} - in_degree: {in_degree[cut_point]} - out_degree: {out_degree[cut_point]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_graph(\n",
    "  graph: dict[str, list[str]],\n",
    "  graph_inv: dict[str, list[str]],\n",
    "  in_degree: dict[str, int],\n",
    "  out_degree: dict[str, int],\n",
    ") -> dict[str, list[str]]:\n",
    "    q = []\n",
    "    \n",
    "    for node in out_degree:\n",
    "      if out_degree[node] == 0:\n",
    "        q.append(node)\n",
    "    \n",
    "    \n",
    "    while len(q) > 0:\n",
    "      node = q.pop(0)\n",
    "      out_degree[node] = -1\n",
    "      \n",
    "      if node not in graph_inv:\n",
    "        continue\n",
    "      \n",
    "      for next_node in graph_inv[node]:\n",
    "        out_degree[next_node] -= 1\n",
    "        if out_degree[next_node] == 0:\n",
    "          q.append(next_node)\n",
    "    \n",
    "    new_graph: dict[str, list[str]] = {}\n",
    "    \n",
    "    for node in graph:\n",
    "      if out_degree[node] == -1:\n",
    "        continue\n",
    "      \n",
    "      new_graph[node] = []\n",
    "      for next_node in graph[node]:\n",
    "        if out_degree[next_node] != -1:\n",
    "          new_graph[node].append(next_node)\n",
    "    \n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_graph = prune_graph(graph, graph_inv, in_degree, out_degree)\n",
    "pruned_cut_points = find_cutpoints(pruned_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_cut_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(graph=pruned_graph, f_set=pruned_cut_points, image_name=\"graph_connections_pruned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"Article\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_clean = [re.sub(r'[^\\w\\s]','',sentence.lower()) for sentence in sentences]\n",
    "stopwords_eng = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = [[words for words in sentence.split() if words not in stopwords_eng] for sentence in sentences_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentence_tokens,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = [ [w2v.wv[word][0] for word in words] for words in sentence_tokens ]\n",
    "max_len = max([len(tokens) for tokens in sentence_tokens])\n",
    "\n",
    "sentence_embeddings = [np.pad(embedding, (0, max_len-len(embedding)), 'constant') for embedding in sentence_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros([len(sentence_tokens), len(sentence_tokens)])\n",
    "\n",
    "for i, row_embedding in enumerate(sentence_embeddings):\n",
    "  for j, column_embedding in enumerate(sentence_embeddings):\n",
    "    similarity_matrix[i][j] = 1-spatial.distance.cosine(row_embedding, column_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph: dict[str, list[str]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s1 in sentence_tokens:\n",
    "  sent1 = ' '.join(s1)\n",
    "  for s2 in sentence_tokens:\n",
    "    sent2 = ' '.join(s2)\n",
    "    \n",
    "    if sent1 not in graph:\n",
    "      graph[sent1] = [sent2]\n",
    "    else:\n",
    "      graph[sent1].append(sent2)\n",
    "    \n",
    "    if sent2 not in graph:\n",
    "      graph[sent2] = [sent1]\n",
    "    else:\n",
    "      graph[sent2].append(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(graph: dict[str, list[str]], weights=None, f_set=None, image_name=\"graph_connections\") -> None:\n",
    "  Q :set[str] = set()\n",
    "  sigma = {'-'}\n",
    "  delta: dict[str, dict[str, set[str]]] = {}\n",
    "\n",
    "  for node in graph:\n",
    "    adj_set = set(graph[node])\n",
    "    Q.add(node)\n",
    "    Q = Q.union(adj_set)\n",
    "    \n",
    "    delta[node] = {'-': adj_set}\n",
    "    # for i in range(len(sentence)-1):\n",
    "    #   word1 = sentence[i]\n",
    "    #   word2 = sentence[i+1]\n",
    "      \n",
    "    #   Q.add(word1)\n",
    "    #   Q.add(word2)\n",
    "      \n",
    "    #   if word1 not in delta:\n",
    "    #     delta[word1] = {'-': {word2}}\n",
    "    #   else:\n",
    "    #     delta[word1]['-'].add(word2)\n",
    "\n",
    "  initialState = sentence_tokens[0][0]\n",
    "  if f_set is None:\n",
    "    F = {}\n",
    "  else:\n",
    "    F = f_set\n",
    "\n",
    "  automata = NFA(Q, sigma, delta, initialState, F)\n",
    "  automata.view(image_name)\n",
    "  \n",
    "  ## Delete .gv file\n",
    "  if os.path.isfile(f\"{image_name}.gv\"):\n",
    "    os.remove(f\"{image_name}.gv\")\n",
    "  \n",
    "  ## Rename .gv.png to .png\n",
    "  if os.path.isfile(f\"{image_name}.gv.png\"):\n",
    "    os.rename(f\"{image_name}.gv.png\", f\"{image_name}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
